{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before starting notebook, need to activate QIIME2 virtual environment\n",
    "# \"source activate qiime2-2017.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning_taxonomy.ipynb        Relative_Abundances.ipynb\r\n",
      "Differential_Abundances.ipynb   Sequence_QC.ipynb\r\n",
      "First_glances_at_data.ipynb     Soil_Properties.ipynb\r\n",
      "OTU_binning.ipynb               Testing_for_Sig_Diffs.ipynb\r\n",
      "Ordination_Plots.ipynb          Tree_for_Unifrac.ipynb\r\n",
      "Plant_Distancs_with_Ellen.ipynb qiime_QC.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "# List all the files in the folder.\n",
    "# You want to see all your sequence XXX.fastq.gz files, R1 and R2 for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: qiime tools import [OPTIONS]\r\n",
      "\r\n",
      "  Import data to create a new QIIME 2 Artifact. See https://docs.qiime2.org/\r\n",
      "  for usage examples and details on the file types and associated semantic\r\n",
      "  types that can be imported.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --type TEXT           The semantic type of the new artifact.  [required]\r\n",
      "  --input-path PATH     Path to file or directory that should be imported.\r\n",
      "                        [required]\r\n",
      "  --output-path PATH    Path where output artifact should be written.\r\n",
      "                        [required]\r\n",
      "  --source-format TEXT  The format of the data to be imported. If not\r\n",
      "                        provided, data must be in the format expected by the\r\n",
      "                        semantic type provided via --type.\r\n",
      "  --help                Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!qiime tools import --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!qiime tools import  --type 'SampleData[PairedEndSequencesWithQuality]' --input-path ../../../data/Seq_data/Seqs/ --source-format CasavaOneEightSingleLanePerSampleDirFmt --output-path demux2.qza\n",
    "# Here we are importing our data\n",
    "# It's in a different format than the data from the tutorial\n",
    "# We received our files from the sequencing centre already demultiplexed -\n",
    "# that is, there is a separate pair of .fastq.gz files (forward and reverse read) for each of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!qiime dada2 plot-qualities --verbose --i-demultiplexed-seqs demux.qza --p-n 4 --o-visualization demux-qualities.qzv\n",
    "# This command will create plots of the quality scores for our sequences\n",
    "# It will be output as demux-qual-plots.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!qiime tools view demux-qualities.qzv\n",
    "# Let's take a look at the read quality plots.\n",
    "# How does it compare to the tutorial reads?\n",
    "# How long are the reads?\n",
    "# Where along the read do sequences get bad?\n",
    "# Do the forward or reverse reads tend to be better quality?\n",
    "\n",
    "# Remember you have to press the square (\"STOP\") button to stop this cell running the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application(s). This may print messages to stdout and/or stderr.\n",
      "The command(s) being run are below. These commands cannot be manually re-run as they will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: run_dada_paired.R /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp2l2jwok2/forward /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp2l2jwok2/reverse /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp2l2jwok2/output.tsv.biom /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp2l2jwok2/filt_f /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp2l2jwok2/filt_r 250 250 12 12 2.0 2 0 1000000\n",
      "\n",
      "R version 3.3.2 (2016-10-31) \n",
      "Loading required package: Rcpp\n",
      "DADA2 R package version: 1.2.2 \n",
      "1) Filtering ................................................................................................................................................................................................................................................\n",
      "2) Learning Error Rates\n",
      "2a) Forward Reads\n",
      "Initial error matrix unspecified. Error rates will be initialized to the maximum possible estimate from this data.\n",
      "Initializing error rates to maximum possible estimate.\n",
      "Sample 1 - 13651 reads in 7134 unique sequences.\n",
      "Sample 2 - 37081 reads in 16964 unique sequences.\n",
      "Sample 3 - 4443 reads in 2088 unique sequences.\n",
      "Sample 4 - 9608 reads in 3809 unique sequences.\n",
      "Sample 5 - 11105 reads in 4092 unique sequences.\n",
      "Sample 6 - 12101 reads in 4813 unique sequences.\n",
      "Sample 7 - 14317 reads in 8289 unique sequences.\n",
      "Sample 8 - 6522 reads in 4161 unique sequences.\n",
      "Sample 9 - 6731 reads in 3986 unique sequences.\n",
      "Sample 10 - 9736 reads in 5551 unique sequences.\n",
      "Sample 11 - 7861 reads in 3947 unique sequences.\n",
      "Sample 12 - 4215 reads in 2398 unique sequences.\n",
      "Sample 13 - 12394 reads in 6293 unique sequences.\n",
      "Sample 14 - 8664 reads in 4329 unique sequences.\n",
      "Sample 15 - 7219 reads in 3654 unique sequences.\n",
      "Sample 16 - 7782 reads in 3404 unique sequences.\n",
      "Sample 17 - 25480 reads in 8146 unique sequences.\n",
      "Sample 18 - 14117 reads in 5356 unique sequences.\n",
      "Sample 19 - 14603 reads in 7163 unique sequences.\n",
      "Sample 20 - 11184 reads in 5346 unique sequences.\n",
      "Sample 21 - 6604 reads in 3541 unique sequences.\n",
      "Sample 22 - 17181 reads in 8365 unique sequences.\n",
      "Sample 23 - 18913 reads in 9057 unique sequences.\n",
      "Sample 24 - 12526 reads in 6170 unique sequences.\n",
      "Sample 25 - 12065 reads in 5978 unique sequences.\n",
      "Sample 26 - 7796 reads in 4246 unique sequences.\n",
      "Sample 27 - 9289 reads in 4847 unique sequences.\n",
      "Sample 28 - 16436 reads in 7885 unique sequences.\n",
      "Sample 29 - 11465 reads in 6406 unique sequences.\n",
      "Sample 30 - 16032 reads in 8415 unique sequences.\n",
      "Sample 31 - 18632 reads in 8086 unique sequences.\n",
      "Sample 32 - 5664 reads in 3009 unique sequences.\n",
      "Sample 33 - 12825 reads in 5633 unique sequences.\n",
      "Sample 34 - 8432 reads in 3699 unique sequences.\n",
      "Sample 35 - 9355 reads in 5137 unique sequences.\n",
      "Sample 36 - 7547 reads in 4409 unique sequences.\n",
      "Sample 37 - 12705 reads in 6859 unique sequences.\n",
      "Sample 38 - 17313 reads in 7899 unique sequences.\n",
      "Sample 39 - 6363 reads in 2475 unique sequences.\n",
      "Sample 40 - 11347 reads in 4119 unique sequences.\n",
      "Sample 41 - 7467 reads in 3391 unique sequences.\n",
      "Sample 42 - 5164 reads in 2389 unique sequences.\n",
      "Sample 43 - 11562 reads in 3276 unique sequences.\n",
      "Sample 44 - 10020 reads in 2680 unique sequences.\n",
      "Sample 45 - 5265 reads in 3189 unique sequences.\n",
      "Sample 46 - 6128 reads in 3708 unique sequences.\n",
      "Sample 47 - 5022 reads in 3409 unique sequences.\n",
      "Sample 48 - 5500 reads in 3726 unique sequences.\n",
      "Sample 49 - 31952 reads in 14648 unique sequences.\n",
      "Sample 50 - 6779 reads in 4099 unique sequences.\n",
      "Sample 51 - 5952 reads in 4031 unique sequences.\n",
      "Sample 52 - 7139 reads in 4471 unique sequences.\n",
      "Sample 53 - 4400 reads in 2822 unique sequences.\n",
      "Sample 54 - 6508 reads in 3725 unique sequences.\n",
      "Sample 55 - 18786 reads in 8616 unique sequences.\n",
      "Sample 56 - 36044 reads in 16355 unique sequences.\n",
      "Sample 57 - 7378 reads in 4986 unique sequences.\n",
      "Sample 58 - 7658 reads in 4864 unique sequences.\n",
      "Sample 59 - 4987 reads in 2818 unique sequences.\n",
      "Sample 60 - 14827 reads in 5171 unique sequences.\n",
      "Sample 61 - 8858 reads in 4872 unique sequences.\n",
      "Sample 62 - 8794 reads in 4556 unique sequences.\n",
      "Sample 63 - 27500 reads in 8652 unique sequences.\n",
      "Sample 64 - 61059 reads in 16901 unique sequences.\n",
      "Sample 65 - 6926 reads in 3865 unique sequences.\n",
      "Sample 66 - 8193 reads in 4608 unique sequences.\n",
      "Sample 67 - 3118 reads in 2094 unique sequences.\n",
      "Sample 68 - 9277 reads in 5317 unique sequences.\n",
      "Sample 69 - 6361 reads in 2929 unique sequences.\n",
      "Sample 70 - 8947 reads in 3971 unique sequences.\n",
      "Sample 71 - 12650 reads in 5987 unique sequences.\n",
      "Sample 72 - 69263 reads in 23306 unique sequences.\n",
      "Sample 73 - 56517 reads in 21969 unique sequences.\n",
      "Sample 74 - 35971 reads in 15599 unique sequences.\n",
      "   selfConsist step 2 \n",
      "   selfConsist step 3 \n",
      "   selfConsist step 4 \n",
      "   selfConsist step 5 \n",
      "   selfConsist step 6 \n",
      "   selfConsist step 7 \n",
      "\n",
      "\n",
      "Convergence after  7  rounds.\n",
      "2b) Reverse Reads\n",
      "Initial error matrix unspecified. Error rates will be initialized to the maximum possible estimate from this data.\n",
      "Initializing error rates to maximum possible estimate.\n",
      "Sample 1 - 13651 reads in 8952 unique sequences.\n",
      "Sample 2 - 37081 reads in 20215 unique sequences.\n",
      "Sample 3 - 4443 reads in 2598 unique sequences.\n",
      "Sample 4 - 9608 reads in 4807 unique sequences.\n",
      "Sample 5 - 11105 reads in 5749 unique sequences.\n",
      "Sample 6 - 12101 reads in 5755 unique sequences.\n",
      "Sample 7 - 14317 reads in 9183 unique sequences.\n",
      "Sample 8 - 6522 reads in 4671 unique sequences.\n",
      "Sample 9 - 6731 reads in 4508 unique sequences.\n",
      "Sample 10 - 9736 reads in 6309 unique sequences.\n",
      "Sample 11 - 7861 reads in 4711 unique sequences.\n",
      "Sample 12 - 4215 reads in 2775 unique sequences.\n",
      "Sample 13 - 12394 reads in 7326 unique sequences.\n",
      "Sample 14 - 8664 reads in 5083 unique sequences.\n",
      "Sample 15 - 7219 reads in 4203 unique sequences.\n",
      "Sample 16 - 7782 reads in 3991 unique sequences.\n",
      "Sample 17 - 25480 reads in 9721 unique sequences.\n",
      "Sample 18 - 14117 reads in 7323 unique sequences.\n",
      "Sample 19 - 14603 reads in 8290 unique sequences.\n",
      "Sample 20 - 11184 reads in 6408 unique sequences.\n",
      "Sample 21 - 6604 reads in 4039 unique sequences.\n",
      "Sample 22 - 17181 reads in 9842 unique sequences.\n",
      "Sample 23 - 18913 reads in 12433 unique sequences.\n",
      "Sample 24 - 12526 reads in 7884 unique sequences.\n",
      "Sample 25 - 12065 reads in 7088 unique sequences.\n",
      "Sample 26 - 7796 reads in 5016 unique sequences.\n",
      "Sample 27 - 9289 reads in 5570 unique sequences.\n",
      "Sample 28 - 16436 reads in 8948 unique sequences.\n",
      "Sample 29 - 11465 reads in 7217 unique sequences.\n",
      "Sample 30 - 16032 reads in 9815 unique sequences.\n",
      "Sample 31 - 18632 reads in 9441 unique sequences.\n",
      "Sample 32 - 5664 reads in 3335 unique sequences.\n",
      "Sample 33 - 12825 reads in 6505 unique sequences.\n",
      "Sample 34 - 8432 reads in 4256 unique sequences.\n",
      "Sample 35 - 9355 reads in 6152 unique sequences.\n",
      "Sample 36 - 7547 reads in 5000 unique sequences.\n",
      "Sample 37 - 12705 reads in 8041 unique sequences.\n",
      "Sample 38 - 17313 reads in 9043 unique sequences.\n",
      "Sample 39 - 6363 reads in 3108 unique sequences.\n",
      "Sample 40 - 11347 reads in 5036 unique sequences.\n",
      "Sample 41 - 7467 reads in 4003 unique sequences.\n",
      "Sample 42 - 5164 reads in 2988 unique sequences.\n",
      "Sample 43 - 11562 reads in 3572 unique sequences.\n",
      "Sample 44 - 10020 reads in 3971 unique sequences.\n",
      "Sample 45 - 5265 reads in 3815 unique sequences.\n",
      "Sample 46 - 6128 reads in 4275 unique sequences.\n",
      "Sample 47 - 5022 reads in 3846 unique sequences.\n",
      "Sample 48 - 5500 reads in 4128 unique sequences.\n",
      "Sample 49 - 31952 reads in 19354 unique sequences.\n",
      "Sample 50 - 6779 reads in 4535 unique sequences.\n",
      "Sample 51 - 5952 reads in 4355 unique sequences.\n",
      "Sample 52 - 7139 reads in 4976 unique sequences.\n",
      "Sample 53 - 4400 reads in 3151 unique sequences.\n",
      "Sample 54 - 6508 reads in 4349 unique sequences.\n",
      "Sample 55 - 18786 reads in 9947 unique sequences.\n",
      "Sample 56 - 36044 reads in 19256 unique sequences.\n",
      "Sample 57 - 7378 reads in 5472 unique sequences.\n",
      "Sample 58 - 7658 reads in 5465 unique sequences.\n",
      "Sample 59 - 4987 reads in 3224 unique sequences.\n",
      "Sample 60 - 14827 reads in 6726 unique sequences.\n",
      "Sample 61 - 8858 reads in 5545 unique sequences.\n",
      "Sample 62 - 8794 reads in 5447 unique sequences.\n",
      "Sample 63 - 27500 reads in 10533 unique sequences.\n",
      "Sample 64 - 61059 reads in 21966 unique sequences.\n",
      "Sample 65 - 6926 reads in 4766 unique sequences.\n",
      "Sample 66 - 8193 reads in 5608 unique sequences.\n",
      "Sample 67 - 3118 reads in 2362 unique sequences.\n",
      "Sample 68 - 9277 reads in 6276 unique sequences.\n",
      "Sample 69 - 6361 reads in 3444 unique sequences.\n",
      "Sample 70 - 8947 reads in 5158 unique sequences.\n",
      "Sample 71 - 12650 reads in 6602 unique sequences.\n",
      "Sample 72 - 69263 reads in 26434 unique sequences.\n",
      "Sample 73 - 56517 reads in 26557 unique sequences.\n",
      "Sample 74 - 35971 reads in 18315 unique sequences.\n",
      "   selfConsist step 2 \n",
      "   selfConsist step 3 \n",
      "   selfConsist step 4 \n",
      "   selfConsist step 5 \n",
      "   selfConsist step 6 \n",
      "\n",
      "\n",
      "Convergence after  6  rounds.\n",
      "\n",
      "3) Denoise remaining samples ......................................................................................................................................................................\n",
      "The sequences being tabled vary in length.\n",
      "4) Remove chimeras\n",
      "5) Write output\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: table2.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: rep-seqs2.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Okay, you're ready to create your OTUs.\n",
    "# But, you have some decisions to make, right?\n",
    "# The command is below, but you need to decide which values to use for \n",
    "# --p-trim-left-f, --p-trim-left-r, --p-trunc-len-f, and --p-trunc-len-r\n",
    "# For the trimming of the reads - remember, look at the quality plots,\n",
    "# and see where the quality drops off. In the tutorial, we used 10\n",
    "# For the truncating of the reads, look at how long they are.\n",
    "# In the tutorial, the reads were 150bp, so we cut them off at 150.\n",
    "# In this data, we produced longer reads. What should that length be?\n",
    "\n",
    "!qiime dada2 denoise-paired --i-demultiplexed-seqs demux2.qza --p-trim-left-f 12 --p-trim-left-r 12 --p-trunc-len-f 250 --p-trunc-len-r 250 --p-max-ee 2 --p-n-threads 0 --verbose --o-table table2 --o-representative-sequences rep-seqs2\n",
    "\n",
    "# On my computer, for full run data,\n",
    "# this started at 1:19AM 86 samples 2:40 fwd reads was at stp3 (converged after 7) 8:12am rev reads step 6 (converged) 9:53 finished denoising 11:05AM finished chimeras and output\n",
    "# I've set it so it takes as much memory as is available\n",
    "# I've also set it so it reports what it's doing below.\n",
    "# That way, you can see the progress it makes as it works its way through\n",
    "# filtering, errors, and each sample\n",
    "# You might want to delegate this task to someone (or a cluster) with a more powerful computer\n",
    "\n",
    "# Need to play with different maxee values (and downstream analyses)\n",
    "\n",
    "# Jamie ran sets of 10 randomly chosen samples, mix of M and O\n",
    "# btw maxee=1 and maxee=2: 3% more OTUs, 10% more sequences\n",
    "# btw maxee=2 and maxee=3: 0% more OTUs, 1% more sequences\n",
    "# Going to use 2 (default, but 1 may be losing unnecessarily much)\n",
    "\n",
    "# For second run of data, with maxee=2, started at 5:54PM on Friday - seemed to start off correctly. Leaving overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: table2.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: rep-seqs2.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's see what our OTU table ended up like...\n",
    "# You'll need to give it a sample-metadata file, formatted as a .tsv\n",
    "# You can make one of these easily in Excel - save it as a \"tab-separated\" file (.tsv)\n",
    "# \n",
    "!qiime feature-table summarize --i-table table2.qza --o-visualization table2.qzv #--m-sample-metadata-filesample-metadata.tsv\n",
    "!qiime feature-table tabulate-seqs --i-data rep-seqs2.qza --o-visualization rep-seqs2.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press the 'q' key, Control-C, or Control-D to quit. This view may no longer be accessible or work correctly after quitting.\n",
      "Press the 'q' key, Control-C, or Control-D to quit. This view may no longer be accessible or work correctly after quitting."
     ]
    }
   ],
   "source": [
    "# Looking at the table summary we just created:\n",
    "!qiime tools view table2.qzv\n",
    "# We got about 10% more sequences with maxee=2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Came back with 9k OTUs, 1.9M seqs - similar seqs to our custom pipeline, but many more OTUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at the representative sequences for each otu:\n",
    "#!qiime tools view rep-seqs.qzv\n",
    "\n",
    "# Check out the possible taxonomy of a couple of OTU sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we need to assign taxonomy to these sequences.\n",
    "# First, extracting the relevant portion of the 16S gene\n",
    "# from the greengenes database\n",
    "\n",
    "# Importing the sequences\n",
    "#!qiime tools import --type FeatureData[Sequence] --input-path 99_otus.fasta --output-path 99_otus.qza\n",
    "# Importing their associated taxonomy\n",
    "#!qiime tools import --type FeatureData[Taxonomy] --input-path 99_otu_taxonomy.txt --output-path ref-taxonomy.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trimming the reads to our target sequence\n",
    "#!qiime feature-classifier extract-reads --i-sequences 99_otus.qza --p-f-primer GTGYCAGCMGCCGCGGTAA --p-r-primer GGACTACNVGGGTWTCTAAT --p-length 500 --o-reads ref-seqs.qza --verbose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And then actually training the classifier based on these sequences\n",
    "#!qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads ref-seqs.qza --i-reference-taxonomy ref-taxonomy.qza --o-classifier Classifier.qza --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also just download the classifier from Canvas posted in the\n",
    "# announcement notifying you of the sequence availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Taxonomy] to: taxonomy2.qza\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Classify our sequences using the classifier\n",
    "\n",
    "!qiime feature-classifier classify --i-classifier ../../classifier.qza --i-reads rep-seqs2.qza --o-classification taxonomy2.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it all in a format we can use in R:\n",
    "!mkdir OTU_table\n",
    "\n",
    "!qiime tools export table2.qza --output-dir OTU_table\n",
    "!qiime tools export rep-seqs2.qza --output-dir OTU_table\n",
    "!qiime tools export taxonomy2.qza --output-dir OTU_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna-sequences2.fasta feature-table2.biom  taxonomy2.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!mv OTU_table/dna-sequences.fasta OTU_table/dna-sequences2.fasta\n",
    "!mv OTU_table/feature-table.biom OTU_table/feature-table2.biom\n",
    "!mv OTU_table/taxonomy.tsv OTU_table/taxonomy2.tsv\n",
    "!ls OTU_table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You also need to make a metadata file for your own samples.\n",
    "# The first column should be your sample names in this format: 523-X-Y\n",
    "# where X is your group number and Y is the sample number.\n",
    "# So, you should have 6 rows plus the title row\n",
    "# Subsequent columns can add other data you may have\n",
    "# E.g., you probably want a Treatment column\n",
    "# If you took pH, make one for that, etc.\n",
    "# To keep things simple, don't use spaces in your column names\n",
    "# and don't start their name with a number\n",
    "\n",
    "# You can just make it in Excel if you want, \n",
    "# and save it as a \"tab-separated\" file with a .tsv extension\n",
    "# (In the example below, it's called sample-metadata.tsv)\n",
    "\n",
    "!biom add-metadata -i ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table2.biom -o ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD2.biom --sample-metadata-fp ../../data/Soil_properties/WBNPNWT_Soils_2015_Metadata_File_QIIME.txt\n",
    "!biom add-metadata -i ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD2.biom -o ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD-tax2.biom --observation-metadata-fp ../../data/Seq_data/QIIME_maxee2/OTU_table/taxonomy2.tsv --sc-separated taxonomy --observation-header OTUID,taxonomy\n",
    "\n",
    "# You should end up with a feature-table.biom file\n",
    "# It should have your samples, their metadata, and your taxonomy all there.\n",
    "# Now you can work with this .biom file in R, like we did in class tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!biom summarize-table -i ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD-tax2.biom -o ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD-tax-summary2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 240\r\n",
      "Num observations: 9140\r\n",
      "Total count: 2135090\r\n",
      "Table density (fraction of non-zero values): 0.019\r\n",
      "\r\n",
      "Counts/sample summary:\r\n",
      " Min: 0.0\r\n",
      " Max: 54113.0\r\n",
      " Median: 6684.000\r\n",
      " Mean: 8896.208\r\n",
      " Std. dev.: 8055.503\r\n",
      " Sample Metadata Categories: Moisture; Project_ID; CEC_cmol_kg; Clay_pct; Land_Class_Unburned; Mn_mg_kg; Sample_ID; ffmc; Burn_Severity_Index; P_mg_kg; Al_mg_kg; Exch_Mg_mg_kg; Sand_pct; K_mg_kg; Land_Class; temp; pH; CFSI; Mean_Duff_Depth_cm; Exch_K_mg_kg; TIC_ash_pct; Mo_mg_kg; fwi; Ca_mg_kg; Forest; Burned_Unburned; Org_or_Min; Veg_Comm; Nutrient; Exch_Na_mg_kg; O_Depth_cm; ws; Replicate; Fwd_Primer_Barcode; Exch_Ca_mg_kg; Mg_mg_kg; Interval; Moisture_Regime; EC_mS_cm; isi; Fire_ID; Sample_Name; Ecosite; prec; Rev_Primer_Barcode; TOC_LOI_pct; Na_mg_kg; Overstory_CBI; Barcodes; rh; TC_pct; Cu_mg_kg; Fe_mg_kg; dc; S_mg_kg; Zn_mg_kg; Silt_pct; Total_N_pct; Dead_Trees; Pct_Exposed_Mineral; Understory_CBI; Community; TOC_HCL_cruc_pct; CBI; RBR; Live_Trees; Total_S_pct; nTrees; bui; Plains; Site_ID; Revcomp_Rev_Primer_Barcode; Severity_Class; dmc\r\n",
      " Observation Metadata Categories: taxonomy\r\n",
      "\r\n",
      "Counts/sample detail:\r\n",
      "15S-WB-U03M-2: 0.0\r\n",
      "15S-WB-05M-2: 0.0\r\n",
      "15S-WB-05O-2: 0.0\r\n",
      "15S-WB-08M-1: 0.0\r\n",
      "15S-WB-07O-1: 0.0\r\n",
      "Blank-1: 13.0\r\n",
      "Blank-22: 36.0\r\n",
      "Blank-13: 51.0\r\n",
      "Blank-10: 53.0\r\n",
      "Blank-17: 65.0\r\n",
      "Blank-11: 100.0\r\n",
      "Blank-4: 150.0\r\n",
      "Blank-8: 172.0\r\n",
      "Blank-16: 193.0\r\n",
      "15S-NT-U07M-1: 1141.0\r\n",
      "15S-NT-50O-2: 1141.0\r\n",
      "JP-CFB-Blank1: 1195.0\r\n",
      "15S-WB-U05O-2: 1677.0\r\n",
      "15S-WB-U03O-1: 1752.0\r\n",
      "15S-NT-39O-1: 2080.0\r\n",
      "15S-NT-43O-1: 2229.0\r\n",
      "15S-NT-U06O-1: 2281.0\r\n",
      "15S-NT-U08O-1: 2331.0\r\n",
      "15S-NT-U09M-1: 2552.0\r\n",
      "JP-CFB-30M: 2605.0\r\n",
      "JP-CFB-11M: 2693.0\r\n",
      "15S-NT-44M-1: 2749.0\r\n",
      "15S-WB-U04M-1: 2782.0\r\n",
      "15S-NT-42O-2: 2855.0\r\n",
      "15S-WB-U02O-2: 2906.0\r\n",
      "15S-WB-U05O-1: 2932.0\r\n",
      "15S-NT-50O-1: 3046.0\r\n",
      "15S-NT-34M-1: 3087.0\r\n",
      "JP-CFB-11T: 3095.0\r\n",
      "15S-NT-22M-2: 3107.0\r\n",
      "15S-NT-32O-1: 3157.0\r\n",
      "15S-WB-09M-1-R: 3159.0\r\n",
      "JP-CFB-17T: 3183.0\r\n",
      "15S-NT-20O-A-1: 3218.0\r\n",
      "JP-CFB-53M: 3253.0\r\n",
      "15S-NT-42O-1: 3274.0\r\n",
      "15S-WB-U04M-2: 3290.0\r\n",
      "15S-WB-U01M-2: 3363.0\r\n",
      "15S-NT-31O-B-1: 3371.0\r\n",
      "15S-WB-U02O-1: 3376.0\r\n",
      "15S-WB-U01O-2: 3391.0\r\n",
      "15S-NT-36O-1: 3399.0\r\n",
      "15S-WB-U04O-2: 3403.0\r\n",
      "15S-WB-U05M-2: 3414.0\r\n",
      "15S-NT-43M-1: 3415.0\r\n",
      "JP-CFB-09M: 3439.0\r\n",
      "15S-WB-U03O-2: 3536.0\r\n",
      "15S-NT-32O-2: 3564.0\r\n",
      "15S-NT-49M-1: 3702.0\r\n",
      "15S-NT-33O-1: 3717.0\r\n",
      "15S-NT-51O-2: 3816.0\r\n",
      "DOE-Blank: 3900.0\r\n",
      "15S-NT-31M-2: 3921.0\r\n",
      "15S-NT-U10M-1: 3977.0\r\n",
      "JP-CFB-53T: 4014.0\r\n",
      "15S-WB-U04O-1: 4067.0\r\n",
      "15S-NT-31O-B-2: 4139.0\r\n",
      "15S-WB-U03M-1: 4141.0\r\n",
      "15S-NT-28M-2: 4212.0\r\n",
      "15S-NT-U07O-2: 4296.0\r\n",
      "15S-NT-47M-2: 4315.0\r\n",
      "15S-NT-52O-2: 4363.0\r\n",
      "15S-NT-21M-2: 4469.0\r\n",
      "15S-NT-52O-1: 4478.0\r\n",
      "15S-WB-U01M-1: 4485.0\r\n",
      "15S-NT-34M-2: 4492.0\r\n",
      "15S-NT-U07M-2: 4522.0\r\n",
      "15S-NT-U10M-2: 4527.0\r\n",
      "15S-NT-U11O-2: 4573.0\r\n",
      "JP-CFB-09T: 4580.0\r\n",
      "15S-NT-33O-2: 4608.0\r\n",
      "15S-NT-U07O-1: 4611.0\r\n",
      "15S-NT-43M-2: 4681.0\r\n",
      "15S-NT-24O-1: 4693.0\r\n",
      "15S-NT-40M-1: 4707.0\r\n",
      "15S-NT-21O-1: 4723.0\r\n",
      "15S-NT-U09M-2: 4731.0\r\n",
      "15S-NT-48O-2: 4782.0\r\n",
      "15S-NT-33M-2: 4784.0\r\n",
      "15S-NT-35O-1: 4837.0\r\n",
      "15S-NT-29O-2: 4863.0\r\n",
      "15S-NT-U12O-2: 4887.0\r\n",
      "15S-NT-51O-1: 4963.0\r\n",
      "15S-NT-43O-2: 5000.0\r\n",
      "15S-NT-35O-2: 5008.0\r\n",
      "15S-NT-39M-1: 5106.0\r\n",
      "15S-NT-U08M-2: 5192.0\r\n",
      "15S-NT-47M-1: 5217.0\r\n",
      "15S-NT-46M-2: 5241.0\r\n",
      "15S-WB-U01O-1: 5298.0\r\n",
      "15S-NT-30O-1: 5346.0\r\n",
      "DOE-BS-2: 5409.0\r\n",
      "15S-NT-26O-2: 5442.0\r\n",
      "15S-NT-45O-2: 5471.0\r\n",
      "15S-NT-23M-1: 5587.0\r\n",
      "15S-NT-31M-1: 5616.0\r\n",
      "15S-NT-U08M-1: 5660.0\r\n",
      "15S-NT-22M-1: 5806.0\r\n",
      "15S-NT-39M-2: 5835.0\r\n",
      "DOE-UBS-2: 5856.0\r\n",
      "15S-NT-23M-2: 6001.0\r\n",
      "DOE-BS-4: 6001.0\r\n",
      "JP-CFB-30T: 6071.0\r\n",
      "DOE-UBS-3: 6149.0\r\n",
      "15S-NT-49M-2: 6166.0\r\n",
      "15S-NT-38M-2: 6209.0\r\n",
      "15S-NT-49O-1: 6244.0\r\n",
      "15S-NT-29O-1: 6250.0\r\n",
      "15S-NT-U09O-1: 6349.0\r\n",
      "15S-NT-27M-1: 6467.0\r\n",
      "15S-NT-38M-1: 6471.0\r\n",
      "JP-CFB-17M: 6583.0\r\n",
      "15S-WB-13O-2: 6643.0\r\n",
      "15S-NT-28O-2: 6644.0\r\n",
      "15S-NT-48O-1: 6682.0\r\n",
      "15S-NT-21O-2: 6686.0\r\n",
      "JP-CFB-23M: 6709.0\r\n",
      "15S-NT-40M-2: 6818.0\r\n",
      "15S-NT-39O-2: 6946.0\r\n",
      "15S-NT-22O-2: 7032.0\r\n",
      "DOE-BS-3: 7070.0\r\n",
      "15S-NT-U06O-2: 7140.0\r\n",
      "15S-NT-U08O-2: 7190.0\r\n",
      "15S-WB-07M-1: 7249.0\r\n",
      "15S-NT-20O-A-2: 7272.0\r\n",
      "15S-WB-14M-2: 7286.0\r\n",
      "15S-NT-44O-2: 7298.0\r\n",
      "15S-NT-44O-1: 7382.0\r\n",
      "15S-WB-10O-1: 7468.0\r\n",
      "15S-WB-09O-2-R: 7538.0\r\n",
      "15S-WB-14O-1: 7565.0\r\n",
      "15S-WB-10O-2: 7585.0\r\n",
      "15S-NT-27O-1: 7869.0\r\n",
      "15S-NT-47O-1: 7884.0\r\n",
      "15S-NT-47O-2: 7928.0\r\n",
      "15S-WB-16O-2: 8019.0\r\n",
      "15S-NT-U09O-2: 8075.0\r\n",
      "15S-WB-01M-2: 8126.0\r\n",
      "DOE-UBS-1: 8188.0\r\n",
      "15S-NT-20O-B-1: 8443.0\r\n",
      "15S-NT-24M-2: 8503.0\r\n",
      "15S-WB-13O-1: 8504.0\r\n",
      "JP-CFB-23T: 8559.0\r\n",
      "15S-NT-31O-A-2: 8599.0\r\n",
      "15S-NT-U12O-1: 8660.0\r\n",
      "15S-WB-12O-2: 8696.0\r\n",
      "15S-NT-26O-1: 8779.0\r\n",
      "15S-WB-01O-2-10x: 9021.0\r\n",
      "15S-NT-25O-2: 9150.0\r\n",
      "15S-NT-20O-B-2: 9352.0\r\n",
      "15S-WB-06O-2: 9359.0\r\n",
      "15S-NT-28O-1: 9391.0\r\n",
      "15S-NT-30M-1: 9499.0\r\n",
      "15S-NT-30O-2: 9524.0\r\n",
      "15S-NT-19O-1: 9544.0\r\n",
      "15S-WB-09O-1-R: 9591.0\r\n",
      "15S-NT-22O-1: 9669.0\r\n",
      "15S-NT-42M-2: 9714.0\r\n",
      "15S-WB-15M-2: 9721.0\r\n",
      "15S-WB-11O-2: 9843.0\r\n",
      "15S-NT-31O-A-1: 9961.0\r\n",
      "15S-NT-46M-1: 10012.0\r\n",
      "15S-WB-10M-1: 10159.0\r\n",
      "15S-WB-11O-1: 10201.0\r\n",
      "15S-WB-01O-1-10x: 10213.0\r\n",
      "15S-WB-09M-2-R: 10227.0\r\n",
      "15S-NT-21M-1: 10285.0\r\n",
      "15S-WB-U05M-1: 10301.0\r\n",
      "15S-NT-40O-1: 10333.0\r\n",
      "15S-WB-01M-1-10x: 10536.0\r\n",
      "15S-WB-06M-2: 10632.0\r\n",
      "15S-NT-23O-2: 10643.0\r\n",
      "15S-NT-44M-2: 10760.0\r\n",
      "15S-NT-24M-1: 10778.0\r\n",
      "15S-NT-36O-2: 11194.0\r\n",
      "15S-NT-U11O-1: 11262.0\r\n",
      "15S-NT-27O-2: 11330.0\r\n",
      "Blank-6: 11368.0\r\n",
      "15S-WB-17O-1: 11407.0\r\n",
      "15S-NT-U10O-2: 11546.0\r\n"
     ]
    }
   ],
   "source": [
    "!head -200 ../../data/Seq_data/QIIME_maxee2/OTU_table/feature-table-metaD-tax-summary2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
