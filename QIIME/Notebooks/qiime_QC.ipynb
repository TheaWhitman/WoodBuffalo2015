{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before starting notebook, need to activate QIIME2 virtual environment\n",
    "# \"source activate qiime2-2017.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "# List all the files in the folder.\n",
    "# You want to see all your sequence XXX.fastq.gz files, R1 and R2 for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: qiime tools import [OPTIONS]\r\n",
      "\r\n",
      "  Import data to create a new QIIME 2 Artifact. See https://docs.qiime2.org/\r\n",
      "  for usage examples and details on the file types and associated semantic\r\n",
      "  types that can be imported.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --type TEXT           The semantic type of the new artifact.  [required]\r\n",
      "  --input-path PATH     Path to file or directory that should be imported.\r\n",
      "                        [required]\r\n",
      "  --output-path PATH    Path where output artifact should be written.\r\n",
      "                        [required]\r\n",
      "  --source-format TEXT  The format of the data to be imported. If not\r\n",
      "                        provided, data must be in the format expected by the\r\n",
      "                        semantic type provided via --type.\r\n",
      "  --help                Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!qiime tools import --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!qiime tools import  --type 'SampleData[PairedEndSequencesWithQuality]' --input-path ../../data/Seq_data/Seqs/ --source-format CasavaOneEightSingleLanePerSampleDirFmt --output-path demux.qza\n",
    "# Here we are importing our data\n",
    "# It's in a different format than the data from the tutorial\n",
    "# We received our files from the sequencing centre already demultiplexed -\n",
    "# that is, there is a separate pair of .fastq.gz files (forward and reverse read) for each of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!qiime dada2 plot-qualities --verbose --i-demultiplexed-seqs demux.qza --p-n 4 --o-visualization demux-qualities.qzv\n",
    "# This command will create plots of the quality scores for our sequences\n",
    "# It will be output as demux-qual-plots.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!qiime tools view demux-qualities.qzv\n",
    "# Let's take a look at the read quality plots.\n",
    "# How does it compare to the tutorial reads?\n",
    "# How long are the reads?\n",
    "# Where along the read do sequences get bad?\n",
    "# Do the forward or reverse reads tend to be better quality?\n",
    "\n",
    "# Remember you have to press the square (\"STOP\") button to stop this cell running the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application(s). This may print messages to stdout and/or stderr.\n",
      "The command(s) being run are below. These commands cannot be manually re-run as they will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: run_dada_paired.R /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp4_1u09fg/forward /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp4_1u09fg/reverse /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp4_1u09fg/output.tsv.biom /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp4_1u09fg/filt_f /var/folders/d2/qqsv2qxd5fjf4k455pzytwgh0000gn/T/tmp4_1u09fg/filt_r 250 250 12 12 1.0 2 0 1000000\n",
      "\n",
      "R version 3.3.2 (2016-10-31) \n",
      "Loading required package: Rcpp\n",
      "DADA2 R package version: 1.2.2 \n",
      "1) Filtering ....................................................................................................................................................x...........................................................................................\n",
      "2) Learning Error Rates\n",
      "2a) Forward Reads\n",
      "Initial error matrix unspecified. Error rates will be initialized to the maximum possible estimate from this data.\n",
      "Initializing error rates to maximum possible estimate.\n",
      "Sample 1 - 11912 reads in 6184 unique sequences.\n",
      "Sample 2 - 32900 reads in 14501 unique sequences.\n",
      "Sample 3 - 3880 reads in 1787 unique sequences.\n",
      "Sample 4 - 8443 reads in 3251 unique sequences.\n",
      "Sample 5 - 9346 reads in 3398 unique sequences.\n",
      "Sample 6 - 10814 reads in 4114 unique sequences.\n",
      "Sample 7 - 12646 reads in 7119 unique sequences.\n",
      "Sample 8 - 5708 reads in 3609 unique sequences.\n",
      "Sample 9 - 6131 reads in 3585 unique sequences.\n",
      "Sample 10 - 8844 reads in 4993 unique sequences.\n",
      "Sample 11 - 7050 reads in 3484 unique sequences.\n",
      "Sample 12 - 3764 reads in 2107 unique sequences.\n",
      "Sample 13 - 10949 reads in 5436 unique sequences.\n",
      "Sample 14 - 7626 reads in 3725 unique sequences.\n",
      "Sample 15 - 6340 reads in 3106 unique sequences.\n",
      "Sample 16 - 6908 reads in 2919 unique sequences.\n",
      "Sample 17 - 22662 reads in 6645 unique sequences.\n",
      "Sample 18 - 11728 reads in 4274 unique sequences.\n",
      "Sample 19 - 13003 reads in 6247 unique sequences.\n",
      "Sample 20 - 9898 reads in 4602 unique sequences.\n",
      "Sample 21 - 5962 reads in 3137 unique sequences.\n",
      "Sample 22 - 15233 reads in 7298 unique sequences.\n",
      "Sample 23 - 15293 reads in 7291 unique sequences.\n",
      "Sample 24 - 10926 reads in 5313 unique sequences.\n",
      "Sample 25 - 10887 reads in 5299 unique sequences.\n",
      "Sample 26 - 6922 reads in 3723 unique sequences.\n",
      "Sample 27 - 8111 reads in 4117 unique sequences.\n",
      "Sample 28 - 14624 reads in 6780 unique sequences.\n",
      "Sample 29 - 10028 reads in 5431 unique sequences.\n",
      "Sample 30 - 14093 reads in 7262 unique sequences.\n",
      "Sample 31 - 16302 reads in 6685 unique sequences.\n",
      "Sample 32 - 5067 reads in 2587 unique sequences.\n",
      "Sample 33 - 11160 reads in 4636 unique sequences.\n",
      "Sample 34 - 7357 reads in 3058 unique sequences.\n",
      "Sample 35 - 8179 reads in 4448 unique sequences.\n",
      "Sample 36 - 6725 reads in 3840 unique sequences.\n",
      "Sample 37 - 11054 reads in 5845 unique sequences.\n",
      "Sample 38 - 15802 reads in 6964 unique sequences.\n",
      "Sample 39 - 5518 reads in 2048 unique sequences.\n",
      "Sample 40 - 10068 reads in 3492 unique sequences.\n",
      "Sample 41 - 6625 reads in 2907 unique sequences.\n",
      "Sample 42 - 4503 reads in 2041 unique sequences.\n",
      "Sample 43 - 9905 reads in 2412 unique sequences.\n",
      "Sample 44 - 7891 reads in 1838 unique sequences.\n",
      "Sample 45 - 4456 reads in 2707 unique sequences.\n",
      "Sample 46 - 5405 reads in 3247 unique sequences.\n",
      "Sample 47 - 4453 reads in 3024 unique sequences.\n",
      "Sample 48 - 4913 reads in 3313 unique sequences.\n",
      "Sample 49 - 27384 reads in 12331 unique sequences.\n",
      "Sample 50 - 6087 reads in 3603 unique sequences.\n",
      "Sample 51 - 5300 reads in 3542 unique sequences.\n",
      "Sample 52 - 6407 reads in 3959 unique sequences.\n",
      "Sample 53 - 3878 reads in 2490 unique sequences.\n",
      "Sample 54 - 5659 reads in 3188 unique sequences.\n",
      "Sample 55 - 16566 reads in 7304 unique sequences.\n",
      "Sample 56 - 31643 reads in 13794 unique sequences.\n",
      "Sample 57 - 6640 reads in 4455 unique sequences.\n",
      "Sample 58 - 6838 reads in 4313 unique sequences.\n",
      "Sample 59 - 4470 reads in 2468 unique sequences.\n",
      "Sample 60 - 13228 reads in 4382 unique sequences.\n",
      "Sample 61 - 7880 reads in 4260 unique sequences.\n",
      "Sample 62 - 7746 reads in 3945 unique sequences.\n",
      "Sample 63 - 23847 reads in 6831 unique sequences.\n",
      "Sample 64 - 52551 reads in 13244 unique sequences.\n",
      "Sample 65 - 5740 reads in 3181 unique sequences.\n",
      "Sample 66 - 7094 reads in 3962 unique sequences.\n",
      "Sample 67 - 2722 reads in 1810 unique sequences.\n",
      "Sample 68 - 8213 reads in 4644 unique sequences.\n",
      "Sample 69 - 5575 reads in 2525 unique sequences.\n",
      "Sample 70 - 7581 reads in 3340 unique sequences.\n",
      "Sample 71 - 11283 reads in 5113 unique sequences.\n",
      "Sample 72 - 61573 reads in 19073 unique sequences.\n",
      "Sample 73 - 50188 reads in 18613 unique sequences.\n",
      "Sample 74 - 32529 reads in 13686 unique sequences.\n",
      "Sample 75 - 19409 reads in 8125 unique sequences.\n",
      "Sample 76 - 13239 reads in 5596 unique sequences.\n",
      "Sample 77 - 38415 reads in 16226 unique sequences.\n",
      "Sample 78 - 11068 reads in 5785 unique sequences.\n",
      "Sample 79 - 4561 reads in 2338 unique sequences.\n",
      "Sample 80 - 3711 reads in 2031 unique sequences.\n",
      "Sample 81 - 3883 reads in 2352 unique sequences.\n",
      "Sample 82 - 5869 reads in 3440 unique sequences.\n",
      "Sample 83 - 2767 reads in 1917 unique sequences.\n",
      "Sample 84 - 5817 reads in 3322 unique sequences.\n",
      "Sample 85 - 3347 reads in 2251 unique sequences.\n",
      "Sample 86 - 13357 reads in 7468 unique sequences.\n",
      "   selfConsist step 2 \n",
      "   selfConsist step 3 \n",
      "   selfConsist step 4 \n",
      "   selfConsist step 5 \n",
      "   selfConsist step 6 \n",
      "   selfConsist step 7 \n",
      "\n",
      "\n",
      "Convergence after  7  rounds.\n",
      "2b) Reverse Reads\n",
      "Initial error matrix unspecified. Error rates will be initialized to the maximum possible estimate from this data.\n",
      "Initializing error rates to maximum possible estimate.\n",
      "Sample 1 - 11912 reads in 7441 unique sequences.\n",
      "Sample 2 - 32900 reads in 16966 unique sequences.\n",
      "Sample 3 - 3880 reads in 2133 unique sequences.\n",
      "Sample 4 - 8443 reads in 3914 unique sequences.\n",
      "Sample 5 - 9346 reads in 4353 unique sequences.\n",
      "Sample 6 - 10814 reads in 4799 unique sequences.\n",
      "Sample 7 - 12646 reads in 7834 unique sequences.\n",
      "Sample 8 - 5708 reads in 3976 unique sequences.\n",
      "Sample 9 - 6131 reads in 3992 unique sequences.\n",
      "Sample 10 - 8844 reads in 5536 unique sequences.\n",
      "Sample 11 - 7050 reads in 4034 unique sequences.\n",
      "Sample 12 - 3764 reads in 2384 unique sequences.\n",
      "Sample 13 - 10949 reads in 6180 unique sequences.\n",
      "Sample 14 - 7626 reads in 4244 unique sequences.\n",
      "Sample 15 - 6340 reads in 3526 unique sequences.\n",
      "Sample 16 - 6908 reads in 3357 unique sequences.\n",
      "Sample 17 - 22662 reads in 7857 unique sequences.\n",
      "Sample 18 - 11728 reads in 5489 unique sequences.\n",
      "Sample 19 - 13003 reads in 7018 unique sequences.\n",
      "Sample 20 - 9898 reads in 5389 unique sequences.\n",
      "Sample 21 - 5962 reads in 3530 unique sequences.\n",
      "Sample 22 - 15233 reads in 8284 unique sequences.\n",
      "Sample 23 - 15293 reads in 9278 unique sequences.\n",
      "Sample 24 - 10926 reads in 6496 unique sequences.\n",
      "Sample 25 - 10887 reads in 6101 unique sequences.\n",
      "Sample 26 - 6922 reads in 4269 unique sequences.\n",
      "Sample 27 - 8111 reads in 4657 unique sequences.\n",
      "Sample 28 - 14624 reads in 7601 unique sequences.\n",
      "Sample 29 - 10028 reads in 6036 unique sequences.\n",
      "Sample 30 - 14093 reads in 8242 unique sequences.\n",
      "Sample 31 - 16302 reads in 7703 unique sequences.\n",
      "Sample 32 - 5067 reads in 2878 unique sequences.\n",
      "Sample 33 - 11160 reads in 5312 unique sequences.\n",
      "Sample 34 - 7357 reads in 3486 unique sequences.\n",
      "Sample 35 - 8179 reads in 5127 unique sequences.\n",
      "Sample 36 - 6725 reads in 4299 unique sequences.\n",
      "Sample 37 - 11054 reads in 6686 unique sequences.\n",
      "Sample 38 - 15802 reads in 7882 unique sequences.\n",
      "Sample 39 - 5518 reads in 2484 unique sequences.\n",
      "Sample 40 - 10068 reads in 4116 unique sequences.\n",
      "Sample 41 - 6625 reads in 3330 unique sequences.\n",
      "Sample 42 - 4503 reads in 2440 unique sequences.\n",
      "Sample 43 - 9905 reads in 2681 unique sequences.\n",
      "Sample 44 - 7891 reads in 2533 unique sequences.\n",
      "Sample 45 - 4456 reads in 3088 unique sequences.\n",
      "Sample 46 - 5405 reads in 3633 unique sequences.\n",
      "Sample 47 - 4453 reads in 3340 unique sequences.\n",
      "Sample 48 - 4913 reads in 3608 unique sequences.\n",
      "Sample 49 - 27384 reads in 15494 unique sequences.\n",
      "Sample 50 - 6087 reads in 3954 unique sequences.\n",
      "Sample 51 - 5300 reads in 3798 unique sequences.\n",
      "Sample 52 - 6407 reads in 4362 unique sequences.\n",
      "Sample 53 - 3878 reads in 2706 unique sequences.\n",
      "Sample 54 - 5659 reads in 3601 unique sequences.\n",
      "Sample 55 - 16566 reads in 8265 unique sequences.\n",
      "Sample 56 - 31643 reads in 15890 unique sequences.\n",
      "Sample 57 - 6640 reads in 4822 unique sequences.\n",
      "Sample 58 - 6838 reads in 4748 unique sequences.\n",
      "Sample 59 - 4470 reads in 2786 unique sequences.\n",
      "Sample 60 - 13228 reads in 5512 unique sequences.\n",
      "Sample 61 - 7880 reads in 4752 unique sequences.\n",
      "Sample 62 - 7746 reads in 4557 unique sequences.\n",
      "Sample 63 - 23847 reads in 8199 unique sequences.\n",
      "Sample 64 - 52551 reads in 16746 unique sequences.\n",
      "Sample 65 - 5740 reads in 3746 unique sequences.\n",
      "Sample 66 - 7094 reads in 4655 unique sequences.\n",
      "Sample 67 - 2722 reads in 2003 unique sequences.\n",
      "Sample 68 - 8213 reads in 5341 unique sequences.\n",
      "Sample 69 - 5575 reads in 2853 unique sequences.\n",
      "Sample 70 - 7581 reads in 4087 unique sequences.\n",
      "Sample 71 - 11283 reads in 5616 unique sequences.\n",
      "Sample 72 - 61573 reads in 21631 unique sequences.\n",
      "Sample 73 - 50188 reads in 21923 unique sequences.\n",
      "Sample 74 - 32529 reads in 15659 unique sequences.\n",
      "Sample 75 - 19409 reads in 9031 unique sequences.\n",
      "Sample 76 - 13239 reads in 6294 unique sequences.\n",
      "Sample 77 - 38415 reads in 18802 unique sequences.\n",
      "Sample 78 - 11068 reads in 6410 unique sequences.\n",
      "Sample 79 - 4561 reads in 2327 unique sequences.\n",
      "Sample 80 - 3711 reads in 2115 unique sequences.\n",
      "Sample 81 - 3883 reads in 2661 unique sequences.\n",
      "Sample 82 - 5869 reads in 3837 unique sequences.\n",
      "Sample 83 - 2767 reads in 2064 unique sequences.\n",
      "Sample 84 - 5817 reads in 3639 unique sequences.\n",
      "Sample 85 - 3347 reads in 2515 unique sequences.\n",
      "Sample 86 - 13357 reads in 8290 unique sequences.\n",
      "   selfConsist step 2 \n",
      "   selfConsist step 3 \n",
      "   selfConsist step 4 \n",
      "   selfConsist step 5 \n",
      "   selfConsist step 6 \n",
      "\n",
      "\n",
      "Convergence after  6  rounds.\n",
      "\n",
      "3) Denoise remaining samples .........................................................................................................................................................\n",
      "The sequences being tabled vary in length.\n",
      "4) Remove chimeras\n",
      "5) Write output\n",
      "\u001b[32mSaved FeatureTable[Frequency] to: table.qza\u001b[0m\n",
      "\u001b[32mSaved FeatureData[Sequence] to: rep-seqs.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Okay, you're ready to create your OTUs.\n",
    "# But, you have some decisions to make, right?\n",
    "# The command is below, but you need to decide which values to use for \n",
    "# --p-trim-left-f, --p-trim-left-r, --p-trunc-len-f, and --p-trunc-len-r\n",
    "# For the trimming of the reads - remember, look at the quality plots,\n",
    "# and see where the quality drops off. In the tutorial, we used 10\n",
    "# For the truncating of the reads, look at how long they are.\n",
    "# In the tutorial, the reads were 150bp, so we cut them off at 150.\n",
    "# In this data, we produced longer reads. What should that length be?\n",
    "\n",
    "!qiime dada2 denoise-paired --i-demultiplexed-seqs demux.qza --p-trim-left-f 12 --p-trim-left-r 12 --p-trunc-len-f 250 --p-trunc-len-r 250 --p-max-ee 1 --p-n-threads 0 --verbose --o-table table --o-representative-sequences rep-seqs\n",
    "\n",
    "# On my computer, for full run data,\n",
    "# this started at 1:19AM 86 samples 2:40 fwd reads was at stp3 (converged after 7) 8:12am rev reads step 6 (converged) 9:53 finished denoising 11:05AM finished chimeras and output\n",
    "# I've set it so it takes as much memory as is available\n",
    "# I've also set it so it reports what it's doing below.\n",
    "# That way, you can see the progress it makes as it works its way through\n",
    "# filtering, errors, and each sample\n",
    "# You might want to delegate this task to someone (or a cluster) with a more powerful computer\n",
    "\n",
    "# Need to play with different maxee values (and downstream analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: table.qzv\u001b[0m\n",
      "\u001b[32mSaved Visualization to: rep-seqs.qzv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's see what our OTU table ended up like...\n",
    "# You'll need to give it a sample-metadata file, formatted as a .tsv\n",
    "# You can make one of these easily in Excel - save it as a \"tab-separated\" file (.tsv)\n",
    "# \n",
    "!qiime feature-table summarize --i-table table.qza --o-visualization table.qzv #--m-sample-metadata-filesample-metadata.tsv\n",
    "!qiime feature-table tabulate-seqs --i-data rep-seqs.qza --o-visualization rep-seqs.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press the 'q' key, Control-C, or Control-D to quit. This view may no longer be accessible or work correctly after quitting.\n",
      "Press the 'q' key, Control-C, or Control-D to quit. This view may no longer be accessible or work correctly after quitting."
     ]
    }
   ],
   "source": [
    "# Looking at the table summary we just created:\n",
    "!qiime tools view table.qzv\n",
    "\n",
    "# How many OTUs are there in each of your samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Came back with 9k OTUs, 1.9M seqs - similar seqs to our custom pipeline, but many more OTUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looking at the representative sequences for each otu:\n",
    "#!qiime tools view rep-seqs.qzv\n",
    "\n",
    "# Check out the possible taxonomy of a couple of OTU sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we need to assign taxonomy to these sequences.\n",
    "# First, extracting the relevant portion of the 16S gene\n",
    "# from the greengenes database\n",
    "\n",
    "# Importing the sequences\n",
    "#!qiime tools import --type FeatureData[Sequence] --input-path 99_otus.fasta --output-path 99_otus.qza\n",
    "# Importing their associated taxonomy\n",
    "#!qiime tools import --type FeatureData[Taxonomy] --input-path 99_otu_taxonomy.txt --output-path ref-taxonomy.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trimming the reads to our target sequence\n",
    "#!qiime feature-classifier extract-reads --i-sequences 99_otus.qza --p-f-primer GTGYCAGCMGCCGCGGTAA --p-r-primer GGACTACNVGGGTWTCTAAT --p-length 500 --o-reads ref-seqs.qza --verbose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And then actually training the classifier based on these sequences\n",
    "#!qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads ref-seqs.qza --i-reference-taxonomy ref-taxonomy.qza --o-classifier Classifier.qza --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also just download the classifier from Canvas posted in the\n",
    "# announcement notifying you of the sequence availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved FeatureData[Taxonomy] to: taxonomy.qza\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Classify our sequences using the classifier\n",
    "\n",
    "!qiime feature-classifier classify --i-classifier ../classifier.qza --i-reads rep-seqs.qza --o-classification taxonomy.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OTU_table: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Save it all in a format we can use in R:\n",
    "!mkdir OTU_table\n",
    "\n",
    "!qiime tools export table.qza --output-dir OTU_table\n",
    "!qiime tools export rep-seqs.qza --output-dir OTU_table\n",
    "!qiime tools export taxonomy.qza --output-dir OTU_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Thea/Documents/Madison/Box Sync/WhitmanLabMaster/WhitmanLab/Projects/WoodBuffalo/WB2015/code/QIIME/Notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You also need to make a metadata file for your own samples.\n",
    "# The first column should be your sample names in this format: 523-X-Y\n",
    "# where X is your group number and Y is the sample number.\n",
    "# So, you should have 6 rows plus the title row\n",
    "# Subsequent columns can add other data you may have\n",
    "# E.g., you probably want a Treatment column\n",
    "# If you took pH, make one for that, etc.\n",
    "# To keep things simple, don't use spaces in your column names\n",
    "# and don't start their name with a number\n",
    "\n",
    "# You can just make it in Excel if you want, \n",
    "# and save it as a \"tab-separated\" file with a .tsv extension\n",
    "# (In the example below, it's called sample-metadata.tsv)\n",
    "\n",
    "!biom add-metadata -i ../OTU_table/feature-table.biom -o ../OTU_table/feature-table-metaD.biom --sample-metadata-fp ../../../data/Soil_properties/WBNPNWT_Soils_2015_Metadata_File_QIIME.txt\n",
    "!biom add-metadata -i ../OTU_table/feature-table-metaD.biom -o ../OTU_table/feature-table-metaD-tax.biom --observation-metadata-fp ../OTU_table/taxonomy.tsv --sc-separated taxonomy --observation-header OTUID,taxonomy\n",
    "\n",
    "# You should end up with a feature-table.biom file\n",
    "# It should have your samples, their metadata, and your taxonomy all there.\n",
    "# Now you can work with this .biom file in R, like we did in class tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!biom summarize-table -i ../OTU_table/feature-table-metaD-tax.biom -o ../OTU_table/feature-table-metaD-tax-summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples: 239\r\n",
      "Num observations: 9028\r\n",
      "Total count: 1914365\r\n",
      "Table density (fraction of non-zero values): 0.019\r\n",
      "\r\n",
      "Counts/sample summary:\r\n",
      " Min: 0.0\r\n",
      " Max: 48895.0\r\n",
      " Median: 5949.000\r\n",
      " Mean: 8009.895\r\n",
      " Std. dev.: 7188.237\r\n",
      " Sample Metadata Categories: CEC_cmol_kg; Project_ID; dc; CBI; Fe_mg_kg; TOC_LOI_pct; Revcomp_Rev_Primer_Barcode; Land_Class_Unburned; ws; Sample_ID; Site_ID; Mn_mg_kg; fwi; rh; bui; dmc; Mg_mg_kg; Live_Trees; Interval; Veg_Comm; prec; TOC_HCL_cruc_pct; Mo_mg_kg; O_Depth_cm; Dead_Trees; Plains; pH; Cu_mg_kg; K_mg_kg; Community; Mean_Duff_Depth_cm; Fire_ID; TC_pct; Nutrient; ffmc; Severity_Class; Ecosite; S_mg_kg; Sand_pct; nTrees; Land_Class; RBR; Rev_Primer_Barcode; Understory_CBI; EC_mS_cm; Sample_Name; Barcodes; Pct_Exposed_Mineral; P_mg_kg; Burned_Unburned; Zn_mg_kg; CFSI; Burn_Severity_Index; Ca_mg_kg; Na_mg_kg; Moisture_Regime; Fwd_Primer_Barcode; isi; Total_N_pct; Total_S_pct; Moisture; Org_or_Min; Overstory_CBI; Clay_pct; Al_mg_kg; temp; Replicate; Silt_pct; TIC_ash_pct; Forest\r\n",
      " Observation Metadata Categories: taxonomy\r\n",
      "\r\n",
      "Counts/sample detail:\r\n",
      "15S-WB-08M-1: 0.0\r\n",
      "15S-WB-U03M-2: 0.0\r\n",
      "15S-WB-05M-2: 0.0\r\n",
      "15S-WB-05O-2: 1.0\r\n",
      "Blank-1: 11.0\r\n",
      "Blank-22: 25.0\r\n",
      "Blank-13: 38.0\r\n",
      "Blank-17: 44.0\r\n",
      "Blank-10: 48.0\r\n",
      "Blank-11: 108.0\r\n",
      "Blank-8: 128.0\r\n",
      "Blank-4: 131.0\r\n",
      "Blank-16: 163.0\r\n",
      "15S-NT-U07M-1: 783.0\r\n",
      "15S-NT-50O-2: 1081.0\r\n",
      "JP-CFB-Blank1: 1098.0\r\n",
      "15S-WB-U03O-1: 1608.0\r\n",
      "15S-WB-U05O-2: 1730.0\r\n",
      "15S-NT-39O-1: 1837.0\r\n",
      "15S-NT-43O-1: 2066.0\r\n",
      "15S-NT-U08O-1: 2068.0\r\n",
      "15S-NT-U06O-1: 2336.0\r\n",
      "15S-NT-U09M-1: 2343.0\r\n",
      "15S-NT-44M-1: 2494.0\r\n",
      "JP-CFB-11M: 2546.0\r\n",
      "15S-WB-U04M-1: 2554.0\r\n",
      "15S-NT-42O-2: 2569.0\r\n",
      "15S-WB-U02O-2: 2671.0\r\n",
      "15S-NT-34M-1: 2706.0\r\n",
      "JP-CFB-11T: 2722.0\r\n",
      "JP-CFB-30M: 2744.0\r\n",
      "JP-CFB-17T: 2757.0\r\n",
      "15S-NT-22M-2: 2781.0\r\n",
      "15S-WB-U05O-1: 2793.0\r\n",
      "15S-WB-09M-1-R: 2805.0\r\n",
      "15S-NT-50O-1: 2809.0\r\n",
      "15S-NT-20O-A-1: 2878.0\r\n",
      "15S-WB-U04M-2: 2920.0\r\n",
      "15S-NT-42O-1: 2977.0\r\n",
      "15S-NT-32O-1: 2984.0\r\n",
      "15S-NT-36O-1: 3011.0\r\n",
      "15S-NT-31O-B-1: 3037.0\r\n",
      "JP-CFB-53M: 3043.0\r\n",
      "15S-NT-43M-1: 3047.0\r\n",
      "15S-WB-U04O-2: 3094.0\r\n",
      "15S-WB-U01O-2: 3104.0\r",
      "\r\n",
      "15S-WB-U03O-2: 3144.0\r\n",
      "15S-WB-U02O-1: 3146.0\r\n",
      "15S-WB-U01M-2: 3151.0\r\n",
      "15S-WB-U05M-2: 3210.0\r\n",
      "JP-CFB-09M: 3213.0\r\n",
      "15S-NT-32O-2: 3252.0\r\n",
      "15S-NT-49M-1: 3325.0\r\n",
      "15S-NT-31M-2: 3436.0\r\n",
      "JP-CFB-53T: 3486.0\r\n",
      "15S-NT-51O-2: 3497.0\r\n",
      "15S-NT-U10M-1: 3523.0\r\n",
      "DOE-Blank: 3583.0\r\n",
      "15S-NT-21M-2: 3672.0\r\n",
      "15S-NT-33O-1: 3677.0\r\n",
      "15S-WB-U03M-1: 3744.0\r\n",
      "15S-WB-U04O-1: 3765.0\r\n",
      "15S-NT-28M-2: 3839.0\r\n",
      "15S-NT-47M-2: 3854.0\r\n",
      "15S-NT-52O-2: 3923.0\r\n",
      "15S-NT-U07O-2: 3930.0\r\n",
      "15S-NT-34M-2: 3941.0\r\n",
      "15S-NT-31O-B-2: 3942.0\r\n",
      "15S-WB-U01M-1: 4014.0\r\n",
      "15S-NT-43M-2: 4035.0\r\n",
      "15S-NT-U11O-2: 4051.0\r\n",
      "15S-NT-52O-1: 4087.0\r\n",
      "15S-NT-40M-1: 4097.0\r\n",
      "15S-NT-U10M-2: 4097.0\r\n",
      "15S-NT-U07M-2: 4110.0\r\n",
      "15S-NT-33O-2: 4251.0\r\n",
      "15S-NT-U07O-1: 4270.0\r\n",
      "15S-NT-24O-1: 4304.0\r\n",
      "JP-CFB-09T: 4348.0\r\n",
      "15S-NT-U12O-2: 4382.0\r\n",
      "15S-NT-35O-1: 4406.0\r\n",
      "15S-NT-48O-2: 4422.0\r\n",
      "15S-NT-U09M-2: 4423.0\r\n",
      "15S-NT-33M-2: 4428.0\r\n",
      "15S-NT-U08M-2: 4447.0\r\n",
      "15S-NT-39M-1: 4448.0\r\n",
      "15S-NT-21O-1: 4452.0\r\n",
      "15S-NT-35O-2: 4480.0\r\n",
      "15S-NT-29O-2: 4553.0\r\n",
      "15S-NT-43O-2: 4563.0\r\n",
      "15S-NT-51O-1: 4576.0\r\n",
      "15S-NT-46M-2: 4707.0\r\n",
      "15S-NT-30O-1: 4772.0\r\n",
      "15S-NT-23M-1: 4854.0\r\n",
      "15S-WB-U01O-1: 4880.0\r\n",
      "15S-NT-47M-1: 4900.0\r\n",
      "15S-NT-26O-2: 4917.0\r\n",
      "DOE-BS-2: 5052.0\r\n",
      "15S-NT-39M-2: 5150.0\r\n",
      "15S-NT-45O-2: 5175.0\r\n",
      "15S-NT-31M-1: 5197.0\r\n",
      "DOE-UBS-2: 5259.0\r\n",
      "15S-NT-22M-1: 5283.0\r\n",
      "15S-NT-U08M-1: 5347.0\r\n",
      "DOE-BS-4: 5363.0\r\n",
      "15S-NT-23M-2: 5378.0\r\n",
      "15S-NT-49M-2: 5452.0\r\n",
      "15S-NT-38M-2: 5644.0\r\n",
      "15S-NT-29O-1: 5647.0\r\n",
      "JP-CFB-30T: 5700.0\r\n",
      "JP-CFB-17M: 5706.0\r\n",
      "DOE-UBS-3: 5757.0\r\n",
      "15S-NT-49O-1: 5782.0\r\n",
      "15S-WB-13O-2: 5793.0\r\n",
      "15S-NT-U09O-1: 5807.0\r\n",
      "15S-NT-27M-1: 5842.0\r\n",
      "15S-NT-44O-2: 5874.0\r\n",
      "15S-NT-28O-2: 5895.0\r\n",
      "15S-NT-40M-2: 5948.0\r\n",
      "JP-CFB-23M: 5949.0\r\n",
      "15S-NT-38M-1: 6003.0\r\n",
      "15S-NT-21O-2: 6202.0\r\n",
      "15S-NT-48O-1: 6211.0\r\n",
      "15S-NT-22O-2: 6242.0\r\n",
      "15S-NT-39O-2: 6276.0\r\n",
      "15S-WB-14M-2: 6286.0\r\n",
      "15S-NT-20O-A-2: 6301.0\r\n",
      "DOE-BS-3: 6384.0\r\n",
      "15S-WB-14O-1: 6508.0\r\n",
      "15S-NT-U08O-2: 6517.0\r\n",
      "15S-NT-44O-1: 6579.0\r\n",
      "15S-WB-10O-1: 6601.0\r\n",
      "15S-WB-10O-2: 6604.0\r\n",
      "15S-NT-U06O-2: 6638.0\r\n",
      "15S-WB-07M-1: 6711.0\r\n",
      "15S-WB-09O-2-R: 6754.0\r\n",
      "15S-NT-31O-A-2: 6929.0\r\n",
      "15S-NT-47O-2: 6965.0\r\n",
      "15S-NT-20O-B-1: 6990.0\r\n",
      "15S-NT-27O-1: 7099.0\r\n",
      "15S-WB-16O-2: 7144.0\r\n",
      "15S-NT-47O-1: 7204.0\r\n",
      "15S-WB-01M-2: 7350.0\r\n",
      "15S-NT-U09O-2: 7359.0\r\n",
      "DOE-UBS-1: 7438.0\r\n",
      "15S-WB-13O-1: 7476.0\r\n",
      "15S-NT-24M-2: 7647.0\r\n",
      "15S-WB-12O-2: 7715.0\r\n",
      "15S-NT-U12O-1: 7735.0\r\n",
      "JP-CFB-23T: 7988.0\r\n",
      "15S-NT-26O-1: 8151.0\r\n",
      "15S-WB-06O-2: 8253.0\r\n",
      "15S-WB-01O-2-10x: 8275.0\r\n",
      "15S-NT-25O-2: 8317.0\r\n",
      "15S-WB-09O-1-R: 8348.0\r\n",
      "15S-NT-28O-1: 8389.0\r\n",
      "15S-NT-20O-B-2: 8436.0\r\n",
      "15S-NT-30M-1: 8524.0\r\n",
      "15S-NT-30O-2: 8546.0\r\n",
      "15S-NT-31O-A-1: 8579.0\r\n",
      "15S-NT-19O-1: 8636.0\r\n",
      "15S-NT-46M-1: 8656.0\r\n",
      "15S-WB-09M-2-R: 8706.0\r\n",
      "15S-NT-42M-2: 8721.0\r\n",
      "15S-WB-11O-2: 8728.0\r\n",
      "15S-NT-22O-1: 8744.0\r\n",
      "15S-WB-11O-1: 8805.0\r\n",
      "15S-WB-10M-1: 8871.0\r\n",
      "15S-WB-15M-2: 8937.0\r\n",
      "15S-NT-21M-1: 9025.0\r\n",
      "15S-WB-01O-1-10x: 9183.0\r\n",
      "15S-WB-U05M-1: 9205.0\r\n",
      "15S-NT-23O-2: 9255.0\r\n",
      "15S-NT-40O-1: 9317.0\r\n",
      "15S-WB-01M-1-10x: 9405.0\r\n",
      "15S-WB-06M-2: 9588.0\r\n",
      "15S-NT-24M-1: 9755.0\r\n",
      "15S-NT-44M-2: 9767.0\r\n",
      "15S-WB-17O-1: 9974.0\r\n",
      "15S-NT-36O-2: 10193.0\r\n",
      "15S-NT-27O-2: 10216.0\r\n",
      "Blank-6: 10263.0\r\n",
      "15S-NT-U11O-1: 10385.0\r\n",
      "15S-NT-U10O-2: 10503.0\r\n",
      "DOE-UBS-4: 10519.0\r\n"
     ]
    }
   ],
   "source": [
    "!head -200 ../OTU_table/feature-table-metaD-tax-summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
